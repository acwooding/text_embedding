{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.algorithms import FastTextEstimator\n",
    "from src.utils import save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets import load_dataset\n",
    "from src.data.estimators import SpacyTokenize\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stopwords\n",
    "import string\n",
    "from src.utils import save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level='DEBUG')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on yelp (not quite properly processed data yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('yelp', num_reviews=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went as a walk-in on a random Wednesday.  Tom was busy, but he squeezed me in.  In about 15 minutes and with very little direction from me I had the tighest fade this side of the Mississippi.  It was pretty neat just to watch him work.  He\\'s truly a master at what he does and I regret every dollar I\\'ve ever spent at those bargain \"value\" chains where the stylists are typically a revolving door of mediocrity.  I challenge you to find a better cut for $14.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yelp Dataset JSON\n",
      "\n",
      "Each file is composed of a single object type, one JSON-object per-line.\n",
      "\n",
      "Take a look at some examples to get you started: https://github.com/Yelp/dataset-examples.\n",
      "\n",
      "Note: the follow examples contain inline comments, which are technically not valid JSON. This is done here to simplify the documentation and explaining the structure, the JSON files you download will not contain any comments and will be fully valid JSON.\n",
      "business.json\n",
      "\n",
      "Contains business data including location data, attributes, and categories.\n",
      "\n",
      "{\n",
      "    // string, 22 character unique string business id\n",
      "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
      "\n",
      "    // string, the business's name\n",
      "    \"name\": \"Garaje\",\n",
      "\n",
      "    // string, the neighborhood's name\n",
      "    \"neighborhood\": \"SoMa\",\n",
      "\n",
      "    // string, the full address of the business\n",
      "    \"address\": \"475 3rd St\",\n",
      "\n",
      "    // string, the city\n",
      "    \"city\": \"San Francisco\",\n",
      "\n",
      "    // string, 2 character state code, if applicable\n",
      "    \"state\": \"CA\",\n",
      "\n",
      "    // string, the postal code\n",
      "    \"postal code\": \"94107\",\n",
      "\n",
      "    // float, latitude\n",
      "    \"latitude\": 37.7817529521,\n",
      "\n",
      "    // float, longitude\n",
      "    \"longitude\": -122.39612197,\n",
      "\n",
      "    // float, star rating, rounded to half-stars\n",
      "    \"stars\": 4.5,\n",
      "\n",
      "    // interger, number of reviews\n",
      "    \"review_count\": 1198,\n",
      "\n",
      "    // integer, 0 or 1 for closed or open, respectively\n",
      "    \"is_open\": 1,\n",
      "\n",
      "    // object, business attributes to values. note: some attribute values might be objects\n",
      "    \"attributes\": {\n",
      "        \"RestaurantsTakeOut\": true,\n",
      "        \"BusinessParking\": {\n",
      "            \"garage\": false,\n",
      "            \"street\": true,\n",
      "            \"validated\": false,\n",
      "            \"lot\": false,\n",
      "            \"valet\": false\n",
      "        },\n",
      "    },\n",
      "\n",
      "    // an array of strings of business categories\n",
      "    \"categories\": [\n",
      "        \"Mexican\",\n",
      "        \"Burgers\",\n",
      "        \"Gastropubs\"\n",
      "    ],\n",
      "\n",
      "    // an object of key day to value hours, hours are using a 24hr clock\n",
      "    \"hours\": {\n",
      "        \"Monday\": \"10:00-21:00\",\n",
      "        \"Tuesday\": \"10:00-21:00\",\n",
      "        \"Friday\": \"10:00-21:00\",\n",
      "        \"Wednesday\": \"10:00-21:00\",\n",
      "        \"Thursday\": \"10:00-21:00\",\n",
      "        \"Sunday\": \"11:00-18:00\",\n",
      "        \"Saturday\": \"10:00-21:00\"\n",
      "    }\n",
      "}\n",
      "\n",
      "review.json\n",
      "\n",
      "Contains full review text data including the user_id that wrote the review and the business_id the review is written for.\n",
      "\n",
      "{\n",
      "    // string, 22 character unique review id\n",
      "    \"review_id\": \"zdSx_SD6obEhz9VrW9uAWA\",\n",
      "\n",
      "    // string, 22 character unique user id, maps to the user in user.json\n",
      "    \"user_id\": \"Ha3iJu77CxlrFm-vQRs_8g\",\n",
      "\n",
      "    // string, 22 character business id, maps to business in business.json\n",
      "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
      "\n",
      "    // integer, star rating\n",
      "    \"stars\": 4,\n",
      "\n",
      "    // string, date formatted YYYY-MM-DD\n",
      "    \"date\": \"2016-03-09\",\n",
      "\n",
      "    // string, the review itself\n",
      "    \"text\": \"Great place to hang out after work: the prices are decent, and the ambience is fun. It's a bit loud, but very lively. The staff is friendly, and the food is good. They have a good selection of drinks.\",\n",
      "\n",
      "    // integer, number of useful votes received\n",
      "    \"useful\": 0,\n",
      "\n",
      "    // integer, number of funny votes received\n",
      "    \"funny\": 0,\n",
      "\n",
      "    // integer, number of cool votes received\n",
      "    \"cool\": 0\n",
      "}\n",
      "\n",
      "user.json\n",
      "\n",
      "User data including the user's friend mapping and all the metadata associated with the user.\n",
      "\n",
      "{\n",
      "    // string, 22 character unique user id, maps to the user in user.json\n",
      "    \"user_id\": \"Ha3iJu77CxlrFm-vQRs_8g\",\n",
      "\n",
      "    // string, the user's first name\n",
      "    \"name\": \"Sebastien\",\n",
      "\n",
      "    // integer, the number of reviews they've written\n",
      "    \"review_count\": 56,\n",
      "\n",
      "    // string, when the user joined Yelp, formatted like YYYY-MM-DD\n",
      "    \"yelping_since\": \"2011-01-01\",\n",
      "\n",
      "    // array of strings, an array of the user's friend as user_ids\n",
      "    \"friends\": [\n",
      "        \"wqoXYLWmpkEH0YvTmHBsJQ\",\n",
      "        \"KUXLLiJGrjtSsapmxmpvTA\",\n",
      "        \"6e9rJKQC3n0RSKyHLViL-Q\"\n",
      "    ],\n",
      "\n",
      "    // integer, number of useful votes sent by the user\n",
      "    \"useful\": 21,\n",
      "\n",
      "    // integer, number of funny votes sent by the user\n",
      "    \"funny\": 88,\n",
      "\n",
      "    // integer, number of cool votes sent by the user\n",
      "    \"cool\": 15,\n",
      "\n",
      "    // integer, number of fans the user has\n",
      "    \"fans\": 1032,\n",
      "\n",
      "    // array of integers, the years the user was elite\n",
      "    \"elite\": [\n",
      "        2012,\n",
      "        2013\n",
      "    ],\n",
      "\n",
      "    // float, average rating of all reviews\n",
      "    \"average_stars\": 4.31,\n",
      "\n",
      "    // integer, number of hot compliments received by the user\n",
      "    \"compliment_hot\": 339,\n",
      "\n",
      "    // integer, number of more compliments received by the user\n",
      "    \"compliment_more\": 668,\n",
      "\n",
      "    // integer, number of profile compliments received by the user\n",
      "    \"compliment_profile\": 42,\n",
      "\n",
      "    // integer, number of cute compliments received by the user\n",
      "    \"compliment_cute\": 62,\n",
      "\n",
      "    // integer, number of list compliments received by the user\n",
      "    \"compliment_list\": 37,\n",
      "\n",
      "    // integer, number of note compliments received by the user\n",
      "    \"compliment_note\": 356,\n",
      "\n",
      "    // integer, number of plain compliments received by the user\n",
      "    \"compliment_plain\": 68,\n",
      "\n",
      "    // integer, number of cool compliments received by the user\n",
      "    \"compliment_cool\": 91,\n",
      "\n",
      "    // integer, number of funny compliments received by the user\n",
      "    \"compliment_funny\": 99,\n",
      "\n",
      "    // integer, number of writer compliments received by the user\n",
      "    \"compliment_writer\": 95,\n",
      "\n",
      "    // integer, number of photo compliments received by the user\n",
      "    \"compliment_photos\": 50\n",
      "}\n",
      "\n",
      "checkin.json\n",
      "\n",
      "Checkins on a business.\n",
      "\n",
      "{\n",
      "    // nested object of the day of the week with key of\n",
      "    // the hour (using a 24hr clock) with the count of checkins\n",
      "    // for that hour (e.g. 14:00 - 14:59).\n",
      "    \"time\": {\n",
      "        \"Wednesday\": {\n",
      "            \"14:00\": 2,\n",
      "            \"16:00\": 1,\n",
      "            \"2:00\": 1,\n",
      "            \"0:00\": 1\n",
      "        },\n",
      "        \"Sunday\": {\n",
      "            \"16:00\": 8,\n",
      "            \"14:00\": 3,\n",
      "            \"15:00\": 3,\n",
      "            \"13:00\": 1,\n",
      "            \"18:00\": 2,\n",
      "            \"23:00\": 1,\n",
      "            \"21:00\": 1,\n",
      "            \"17:00\": 2\n",
      "        },\n",
      "        \"Friday\": {\n",
      "            \"16:00\": 1,\n",
      "            \"13:00\": 1,\n",
      "            \"11:00\": 2,\n",
      "            \"23:00\": 2\n",
      "        },\n",
      "    },\n",
      "\n",
      "    // string, 22 character business id, maps to business in business.json\n",
      "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\"\n",
      "}\n",
      "\n",
      "tip.json\n",
      "\n",
      "Tips written by a user on a business. Tips are shorter than reviews and tend to convey quick suggestions.\n",
      "\n",
      "{\n",
      "    // string, text of the tip\n",
      "    \"text\": \"Secret menu - fried chicken sando is da bombbbbbb Their zapatos are good too.\",\n",
      "\n",
      "    // string, when the tip was written, formatted like YYYY-MM-DD\n",
      "    \"date\": \"2013-09-20\",\n",
      "\n",
      "    // integer, how many likes it has\n",
      "    \"likes\": 172,\n",
      "\n",
      "    // string, 22 character business id, maps to business in business.json\n",
      "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
      "\n",
      "    // string, 22 character unique user id, maps to the user in user.json\n",
      "    \"user_id\": \"49JhAJh8vSQ-vM4Aourl0g\"\n",
      "}\n",
      "\n",
      "photo.json\n",
      "\n",
      "Contains photo data including the caption and classification (one of \"food\", \"drink\", \"menu\", \"inside\" or \"outside\").\n",
      "\n",
      "{\n",
      "    // string, 22 character unique photo id\n",
      "    \"photo_id\": \"_nN_DhLXkfwEkwPNxne9hw\",\n",
      "\n",
      "\n",
      "    // string, 22 character business id, maps to business in business.json\n",
      "    \"business_id\" : \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
      "\n",
      "    // string, the photo caption, if any\n",
      "    \"caption\" : \"carne asada fries\",\n",
      "\n",
      "    // string, the category the photo belongs to, if any\n",
      "    \"label\" : \"food\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SpacyTokenize(n_threads=6, punctuation=string.punctuation, stopwords=stopwords, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpacyTokenize(batch_size=50, language_model='en_core_web_sm', lemmatize=True,\n",
       "       n_threads=6, punctuation='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~',\n",
       "       stopwords=frozenset({'now', 'anyhow', 'front', 'something', 'however', 'below', 'four', 'latterly', 'seemed', 'thereafter', 'we', 'these', 'whether', 'is', 'a', 'whereupon', 'out', 'in', 'me', 'mostly', 'if', 'becomes', 'per', 'sometimes', 'were', 'whereas', 'twelve', 'yourself', 'system', 'too', 'e...', 'after', 'could', 'towards', 'through', 'thereby', 'by', 'sometime', 'often', 'for', 'describe'}))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit(ds.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tokenizer.transform(ds.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-05 14:45:59,057 - word2vec - INFO - collecting all words and their counts\n",
      "2018-10-05 14:45:59,059 - word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-10-05 14:45:59,074 - word2vec - INFO - collected 8006 word types from a corpus of 54651 raw words and 9747 sentences\n",
      "2018-10-05 14:45:59,076 - word2vec - INFO - Loading a fresh vocabulary\n",
      "2018-10-05 14:45:59,083 - word2vec - INFO - effective_min_count=5 retains 1780 unique words (22% of original 8006, drops 6226)\n",
      "2018-10-05 14:45:59,084 - word2vec - INFO - effective_min_count=5 leaves 45048 word corpus (82% of original 54651, drops 9603)\n",
      "2018-10-05 14:45:59,090 - word2vec - INFO - deleting the raw counts dictionary of 8006 items\n",
      "2018-10-05 14:45:59,092 - word2vec - INFO - sample=0.001 downsamples 60 most-common words\n",
      "2018-10-05 14:45:59,093 - word2vec - INFO - downsampling leaves estimated 39968 word corpus (88.7% of prior 45048)\n",
      "2018-10-05 14:45:59,236 - fasttext - INFO - estimated required memory for 1780 words, 16788 buckets and 300 dimensions: 25632304 bytes\n",
      "2018-10-05 14:45:59,238 - word2vec - INFO - resetting layer weights\n",
      "2018-10-05 14:46:00,782 - fasttext - INFO - Total number of ngrams is 16788\n",
      "2018-10-05 14:46:01,289 - base_any2vec - INFO - training model with 3 workers on 1780 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-10-05 14:46:01,596 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 14:46:01,610 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 14:46:01,663 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 14:46:01,664 - base_any2vec - INFO - EPOCH - 1 : training on 54651 raw words (39958 effective words) took 0.3s, 119346 effective words/s\n",
      "2018-10-05 14:46:01,958 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 14:46:01,963 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 14:46:02,005 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 14:46:02,006 - base_any2vec - INFO - EPOCH - 2 : training on 54651 raw words (39974 effective words) took 0.3s, 132223 effective words/s\n",
      "2018-10-05 14:46:02,298 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 14:46:02,305 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 14:46:02,348 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 14:46:02,349 - base_any2vec - INFO - EPOCH - 3 : training on 54651 raw words (39949 effective words) took 0.3s, 131805 effective words/s\n",
      "2018-10-05 14:46:02,647 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 14:46:02,698 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 14:46:02,745 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 14:46:02,746 - base_any2vec - INFO - EPOCH - 4 : training on 54651 raw words (39937 effective words) took 0.4s, 110213 effective words/s\n",
      "2018-10-05 14:46:03,051 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 14:46:03,079 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 14:46:03,094 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 14:46:03,095 - base_any2vec - INFO - EPOCH - 5 : training on 54651 raw words (39943 effective words) took 0.3s, 130848 effective words/s\n",
      "2018-10-05 14:46:03,098 - base_any2vec - INFO - training on a 273255 raw words (199761 effective words) took 1.8s, 110547 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = FastTextEstimator(min_count=5, min_n=3, max_n=6,size=300, sg=1,window=10,word_ngrams=1, iter=5,random_state=42)\n",
    "model.fit(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.5 ms, sys: 4.63 ms, total: 72.1 ms\n",
      "Wall time: 70.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding = model.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1780, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using the train_model script\n",
    "\n",
    "```\n",
    "## train / fit / build models\n",
    "train: models/model_list.json\n",
    "\t$(PYTHON_INTERPRETER) -m src.models.train_model model_list.json\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.025,\n",
       " 'batch_words': 10000,\n",
       " 'bucket': 2000000,\n",
       " 'callbacks': (),\n",
       " 'cbow_mean': 1,\n",
       " 'hashfxn': <function hash(obj, /)>,\n",
       " 'hs': 0,\n",
       " 'iter': 5,\n",
       " 'max_n': 6,\n",
       " 'max_vocab_size': None,\n",
       " 'min_alpha': 0.0001,\n",
       " 'min_count': 5,\n",
       " 'min_n': 3,\n",
       " 'negative': 5,\n",
       " 'ns_exponent': 0.75,\n",
       " 'null_word': 0,\n",
       " 'random_state': 42,\n",
       " 'restrict_to_corpus': True,\n",
       " 'sample': 0.001,\n",
       " 'sg': 1,\n",
       " 'size': 300,\n",
       " 'sorted_vocab': 1,\n",
       " 'trim_rule': None,\n",
       " 'window': 10,\n",
       " 'word_ngrams': 1,\n",
       " 'workers': 3}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_spec =  [{'dataset': 'yelp',\n",
    "  'dataset_params': {'num_reviews': 1000},\n",
    "  'algorithm': 'fasttext',\n",
    "  'algorithm_params': {'iter': 5,\n",
    "     'max_n': 6,\n",
    "     'min_count': 5,\n",
    "     'min_n': 3,\n",
    "     'random_state': 42,\n",
    "     'sg': 1,\n",
    "     'size': 300,\n",
    "     'window': 10,\n",
    "     'word_ngrams': 1}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ava00125/src/devel/text_embedding/models')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(model_path / 'test_model_list.json', json_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-05 15:30:17,188 - train_model - INFO - Building models from ../models/test_model_list.json\n",
      "2018-10-05 15:30:17,213 - word2vec - INFO - collecting all words and their counts\n",
      "2018-10-05 15:30:17,213 - word2vec - WARNING - Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "2018-10-05 15:30:17,213 - word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-10-05 15:30:17,334 - word2vec - INFO - collected 102 word types from a corpus of 666833 raw words and 1000 sentences\n",
      "2018-10-05 15:30:17,334 - word2vec - INFO - Loading a fresh vocabulary\n",
      "2018-10-05 15:30:17,335 - word2vec - INFO - effective_min_count=5 retains 90 unique words (88% of original 102, drops 12)\n",
      "2018-10-05 15:30:17,335 - word2vec - INFO - effective_min_count=5 leaves 666813 word corpus (99% of original 666833, drops 20)\n",
      "2018-10-05 15:30:17,336 - word2vec - INFO - deleting the raw counts dictionary of 102 items\n",
      "2018-10-05 15:30:17,337 - word2vec - INFO - sample=0.001 downsamples 29 most-common words\n",
      "2018-10-05 15:30:17,337 - word2vec - INFO - downsampling leaves estimated 139311 word corpus (20.9% of prior 666813)\n",
      "2018-10-05 15:30:17,339 - fasttext - INFO - estimated required memory for 90 words, 90 buckets and 300 dimensions: 374040 bytes\n",
      "2018-10-05 15:30:17,340 - word2vec - INFO - resetting layer weights\n",
      "2018-10-05 15:30:18,633 - fasttext - INFO - Total number of ngrams is 90\n",
      "2018-10-05 15:30:18,831 - base_any2vec - INFO - training model with 3 workers on 90 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-10-05 15:30:19,862 - base_any2vec - INFO - EPOCH 1 - PROGRESS: at 73.00% examples, 99681 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-05 15:30:20,205 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 15:30:20,233 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 15:30:20,253 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 15:30:20,253 - base_any2vec - INFO - EPOCH - 1 : training on 666833 raw words (139134 effective words) took 1.4s, 99237 effective words/s\n",
      "2018-10-05 15:30:21,283 - base_any2vec - INFO - EPOCH 2 - PROGRESS: at 70.30% examples, 94912 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-05 15:30:21,643 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 15:30:21,659 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 15:30:21,662 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 15:30:21,662 - base_any2vec - INFO - EPOCH - 2 : training on 666833 raw words (139219 effective words) took 1.4s, 99491 effective words/s\n",
      "2018-10-05 15:30:22,684 - base_any2vec - INFO - EPOCH 3 - PROGRESS: at 71.70% examples, 96962 words/s, in_qsize 6, out_qsize 1\n",
      "2018-10-05 15:30:23,017 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 15:30:23,048 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 15:30:23,049 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 15:30:23,049 - base_any2vec - INFO - EPOCH - 3 : training on 666833 raw words (139150 effective words) took 1.4s, 100377 effective words/s\n",
      "2018-10-05 15:30:24,080 - base_any2vec - INFO - EPOCH 4 - PROGRESS: at 73.00% examples, 98529 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-05 15:30:24,415 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 15:30:24,441 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 15:30:24,445 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 15:30:24,445 - base_any2vec - INFO - EPOCH - 4 : training on 666833 raw words (139145 effective words) took 1.4s, 100219 effective words/s\n",
      "2018-10-05 15:30:25,485 - base_any2vec - INFO - EPOCH 5 - PROGRESS: at 74.10% examples, 99572 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-05 15:30:25,786 - base_any2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-05 15:30:25,820 - base_any2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-05 15:30:25,829 - base_any2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-05 15:30:25,829 - base_any2vec - INFO - EPOCH - 5 : training on 666833 raw words (138798 effective words) took 1.4s, 100939 effective words/s\n",
      "2018-10-05 15:30:25,829 - base_any2vec - INFO - training on a 3334165 raw words (695446 effective words) took 7.0s, 99383 effective words/s\n"
     ]
    }
   ],
   "source": [
    "!python -m src.models.train_model ../models/test_model_list.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"fasttext_yelp_0\": {\r\n",
      "    \"algorithm\": \"fasttext\",\r\n",
      "    \"algorithm_params\": {\r\n",
      "      \"iter\": 5,\r\n",
      "      \"max_n\": 6,\r\n",
      "      \"min_count\": 5,\r\n",
      "      \"min_n\": 3,\r\n",
      "      \"random_state\": 42,\r\n",
      "      \"sg\": 1,\r\n",
      "      \"size\": 300,\r\n",
      "      \"window\": 10,\r\n",
      "      \"word_ngrams\": 1\r\n",
      "    },\r\n",
      "    \"data_hash\": \"a52cc09f060399dd42dee0ed3f214c686cd46bb0\",\r\n",
      "    \"dataset\": \"yelp\",\r\n",
      "    \"dataset_params\": {\r\n",
      "      \"num_reviews\": 1000\r\n",
      "    },\r\n",
      "    \"model_hash\": \"1e20f8b8d4abab2722cecee94a4753bc7aef71e5\",\r\n",
      "    \"run_number\": 0,\r\n",
      "    \"target_hash\": \"38f65f3b11da4851aaaccc19b1f0cf4d3806f83b\"\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ../models/trained_models.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:text_embedding]",
   "language": "python",
   "name": "conda-env-text_embedding-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
